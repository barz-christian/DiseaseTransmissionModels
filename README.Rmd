---
title: "Disease transition modeling in stan"
date: "creation date: 29-07-2020, update date: `r lubridate::today()`"
output:
  github_document:
    toc: true
    toc_depth: 2
    pandoc_args: --webtex
---

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(fig.path="Figs/", 
                      message=FALSE,
                      warning=FALSE,
                      echo=TRUE, 
                      #results="hide", 
                      fig.width=11)
```

# Remark

Although this note deals with epidemiological questions, it was written to 
explain how to implement a model based on a system of differential equations in 
`Stan`.

**I still not found a solution to display math symbols in a way like in `latex`**

# Introduction {.tabset}

The following markdown file is inspired by the case study [Bayesian workflow for disease transmission modeling in Stan](https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html).

## Outline 

In this note we want to model the outbreak of a disease using a compartment model, more precisely a Susceptible-Infected-Recovered (SIR) model, and show how we can solve the corresponding systems of differential equations in Stan. More precisely we solve systems of differential equations, where the parameters of the system are considered as random variable. The distribution of these parameters are determined by a bayesian model.
In this note we want to show how both things can be done in `Stan`.

In particular we will compute useful epidemilogical parameters as the *basic reproduction rate* $R_0$.

1. In section 1 we introduce how to build, fit and diagnose compartment models
2. In section 2 we review how simulated data can be used to examine our model and priors and provide an introduction to inference calibration.
3. In section 3 we do a pragmatic discussion on how to efficiently implement and scale up ordinary differential equations in Stan.

## compartment models

*Population based models* subdivide the total population into homogeneous groups, which we call *compartments*.
The flow between the compartments can be described by a system of differential equations. 

In our example the compartments are defined that their individuals are in the same state, i.e. the individuals are

- susceptible,
- infected or have
- recovered (or removed).

The time-dependent number of people in each compartment will be given as the solution of a system of ordinary differential equations.


## setup and reproducibility

```{r}
library(pacman)
p_load(
  tidyverse, 
  lubridate, # date time operations
  outbreaks, # data
  rstan, # use Stan in R
  survminer, # Kaplan meier plot
  gridExtra, # graphics
  DT # display tables
)

rstan_options (auto_write = TRUE)
options (mc.cores = parallel::detectCores ())

set.seed(3)

sessionInfo()
```

# Simple susceptile-infected-recovered model (SIR) {.tabset}

A susceptile-infected-recovered model [SIR](https://de.wikipedia.org/wiki/SIR-Modell) is a classical epidemiological model to describe the outbreak of diseases with immunization. It is named after its compartments, i.e. S, I, and R stand for:
	

+ S - susceptible. These are people that are not infected with the disease yet. However, they are not immune to it either and so they can become infected with the disease in the future.
	
+ I - infected or infectious. These are people that are infected with the disease and can transmit the disease to susceptible people.
	
+ R - recovered. These are people who have recovered from the disease and are immune, so they can no longer be infected with the disease. 

**Remark:** A [SEIR model](https://de.wikipedia.org/wiki/SEIR-Modell) would include the latency stage, i.e. the time until an infected person can infect others. We will show how to implement a SEIR model using Stan in an upcoming note. 

A complete discussion of a SIR-model is given in the subsection [Mathematical transmission model](#SIR_model)

## data

In our example we are examine an outbreak of influenza A (H1N1) in 1978 at a british school. The data is freely available in the R package `outbreaks` and consists of the daily number of students in bed spanning over a time interval of 14 days.

There were 763 male students and 512 of them became ill. It is reported that one infected boy started the epidemic, which spreads in the relativly closed community.

We load the data and inspect it:

```{r DataLoad}
df <- influenza_england_1978_school
knitr::kable(df)
```


```{r DataInspection}
df %>% ggplot() + 
  geom_point(mapping = aes(x = date, y = in_bed)) +
  labs(y = "number of students in bed")
```

## SIR-Model {#SIR_model}

The susceptible-infected-recoved model (SIR) splits the population in three time-dependent compartments:

- the susceptible (infectable)
- the infected (and infectious)
- the recovered (and not infectious)

We assume when an susceptible individual comes into contact with an infectious individual, the former becomes infected for some time. Afterwards it recovers and beomes immune.

We model the above dynamics by the following system of ordinary differential equations:

$$
\begin{aligned}
\frac{S}{dt} = & -\beta S \frac{I}{N} \\
\frac{dI}{dt} = & \beta S\frac{I}{N} - \gamma I \\
\frac{dR}{dt} = & \gamma I
\end{aligned}
$$


where :

- $S(t)$ is the number of people susceptible to becoming infected (no immunity),
- $I(t)$ is the number of people currently infected (and infectious),
- $R(t)$ is the number of recovered people (we assume they remain immune indefinitely),
- $N$ is the total number of the population,
- $\beta$ is the constant rate of infectious contact between people,
- $\gamma$ the constant recovery rate of infected individuals.

The system of ODEs has the following intuition:
The proportion of infected people among the population is $\frac{I}{N}$, which can be considered as the probability of disease transmission when a susceptible and an infected subject come in contact. 
Let $\beta$ be the average number of contacts per person per time.
At each time step, assuming uniform contacts, the probability for a susceptible person to become infected is $\beta\frac{I}{N}$. 

$\lambda=\beta\frac{I}{N}$ is called force of infection and measures the probability per time unit that a susceptible person becomes infected.

Hence at each time step $\beta S \frac{I}{N}$ susceptible individuals become infected and hence $\beta S \frac{I}{N}$ individuals leaving the compartment $S$ and $\beta S \frac{I}{N}$ enter the compartment $I$.

Let $\gamma$ denote the revovery rate. Hence the number of infected people decreases with a speed of $\gamma I$ and is equal to the grows of the compartment $R$.

### Basic reproduction number

The number $R_0=\frac{\beta}{\gamma}$ is called the *basic reproduction number*. It measures the number of new infections are caused by one infected person.


### initial conditions

The disease has started wich one infected individual which gives the following initial conditions:

1. $S(0)  =  N-1$
2. $I(0)  =  1$
3. $R(0)  =  0$

### model assumptions

The above model holds under the following assumptions:

- Birth and deaths are not contributing to the dynamics and the total population $N=S+I+R$ is constant.
- Recovered individuals do not become susceptible again over time.
- The infection rate $\beta$ and recovery rate $\gamma$ are constant.
- The population is homogeneous.
- Individuals meet any other individual uniformliy at random (homogeneous mixing) and recovery time follows an exponential distribution with mean $\frac{1}{\gamma}$.
- eplacing the integer number of people in each compartement by a continuous approximation is legitimate (the population is big enough)

## statistical model

We can solve the system of differential equation, the SIR-model, for example using a Runge-Kutta method. But beside the initial conditions $S(0),I(0),R(0)$ we have to chose values for the parameters $\beta$ and $\gamma$. This is the part were bayesian statistics is joining the party. So let us recall some basics from bayesian statistics:

### Bayes rule

We recall some notation first: Let $A$ and $B$ be two events, then the conditional probability of $A$ given $B$, denoted by $P(A|B)$, is the likelihood of observing event $A$ given that $B$ is true. Then **Bayes rule** is the following formula:

$$
P(A|B)=\frac{P(B|A)P(A)}{P(B)}.
$$

To understand Bayes rule bettter we slightly change our notation (point of view): We denote by $\mathcal{H}$ our hypothesis, given by our model, which is determined by its parameters. It is up to you wether you read $\mathcal{H}$ as hypothesis, model or parameter. Moreover we denote by $D$ our data. 

Usually we ask a question like: How likely is hypothesis $\mathcal{H}$ given the data $D$?

This question is equal to $P(\mathcal{H}|D)$  and Bayes rule, written in the new notation,

$$
P(\mathcal{H}|D)=\frac{P(D|\mathcal{H})P(\mathcal{H})}{P(D)}
$$
tells us (some)how to compute it. But let us give an interpretation of the formula first:

- The **prior distribution** $P(\mathcal{H})$ captures our intial beliefs, that the hypothesis is true or in other words how the values of the parameter are distributed.
- The **posterior distribution** $P(\mathcal{H}|D)$ are our beliefs about the hypothesis after we saw the data.
- The **likelihood distribution** or **sampling dsitribution** $P(D|\mathcal{H})$ measures how likely it is to observe the data $D$ given the hypothesis $\mathcal{H}$.
- $P(D)$ is called the **marginal distribution**, which will not have an interpretation for us. My reason is, that for a pure mathematical point of view we do not need an interpretation, but for non mathematicians such an interpretation can be really helpful and in particular it can be used to bridge "mathematical gaps" and replace precise mathematical explaination, which are often useless for non mathematicians.


We remark that specifying a prior is a big advantage of the bayesian approach, as it allows us to include expert knowledge, e.g. the recovery time is positve and around a day. 

### Sampling distribution

Assume the parameters and initial conditions are given, then the compartment model defines a unique solution for each compartment, including the number of infected people, $I_{ODE}(t)$. We want to link this solution to the observed data, i.e. number of students in bed, $I_{obs}(t)$, at each time point. As the latter is a noisy estimate of the true number of infected people, we chose to model this number $I_{obs}(t)$ with a count distribution, precisely the negative binomial distribution. This distribution allows us to use the observation $I_{obs}(t)$ as the expected value and account over-dispersion by the parameter $\phi$:

$$
I_{obs}(t)\sim NegBin(I_{ODE}(t),\phi).
$$

This gives us $P(D|\mathcal{H})$ with the parameters of our model $\mathcal{H}=(\beta,\gamma,\phi)$.

### Prior distribution

Next we need to specify a prior distribution $P(\mathcal{H})$ with $\mathcal{H},(\beta,\gamma,\phi)$. We will specify one for each of the parameters. 

We specify the recovery rate (truncated at 0, see code section) by

$$
\gamma\sim normal(0.4,0.5)
$$ 

which expresses our beliefs, that $\gamma$ has to be positive and the probability that the recovery time is bigger than a day is a priori 90%. Of course we can change this prior according to expert knowledge and if more information become available.

The "infection rate" is specified by
$$
\beta\sim normal(2,1)
$$ 
and will be truncated at 0 (see code section).

The prior of the inverse of the "dispersion" parameter is assumed to be exponentially distributed:
$$
\phi_{inv}\sim exponential(5)
$$

### Predictions and derived quantities

After fitting the model we obtain the posterior distribution $P(\mathcal{H}|D)$ from which we can derive additional quantities of interest, e.g. the basic repoduction number $R_0=\frac{\beta}{\gamma}$.
More precisely the bayesian inference allows us to construct a posterior distribution for this quantity
$$
P(R_0|D).
$$

We can also compute predictions by
$$
P(D_{pred}|D)=\int P(D_{pred}|\mathcal{H})P(\mathcal{H}|D)d\mathcal{H}
$$
and we 


# Coding : Stan {.tabset}

In this section show how a system of ordinary differential equations, e.g. a susceptible-infected-recovered model (SIR), can be solved in `Stan`.
We assume that the reader has some basic knowledge about `Stan` and/or `rstan`.

## Coding ODEs in Stan

Let the following ODE be given :

$$
\frac{y}{dt} = f(t,y)
$$
where $y$ are the *states*, in our example $y = (S,I,R)$ and $t$ is the time. We denote the initial conditions by $y_0$ and $t_0$ and by $\tau$ the times at which we evaluate the solution.

In order to specify an ODE in Stan, we first code $f$ in the `function block`. This function must observe a strict signature:

```
real[] f(real time, real[] state, real[] theta, real[] x_r, int[] x_i)
```

with

- `time` $t$,
- `state`, the volumnes of each compartment, $y$
- `theta`, variables used to compute $f$, which depend on the model parameters,
- `x_r`, real variables used to evaluate $f$, which only depend on fixed data,
- `x_i`, ingeter values used to evaluate $f$, which only depend on fixed data.

In our example the ODE for the susceptile-infected-recovered model is defined as follows:

```
functions {
  real[] sir(real t, real[] y, real[] theta, 
             real[] x_r, int[] x_i) {

      real S = y[1];
      real I = y[2];
      real R = y[3];
      real N = x_i[1];
      
      real beta = theta[1];
      real gamma = theta[2];
      
      real dS_dt = -beta * I * S / N;
      real dI_dt =  beta * I * S / N - gamma * I;
      real dR_dt =  gamma * I;
      
      return {dS_dt, dI_dt, dR_dt};
  }
}
```

We will use one of Stan's numerical integrators, Runge-Kutta of 4th/5th order, to solve the set of equations.

The integrator call looks as follows:

```
    y = integrate_ode_rk45(sir, y0, t0, ts, theta, x_r, x_i);
```

with 

- `sir` is the name of the function that returns the derivatives $f$,
- `y_0` is the initial condition,
- `t_0` is the time of the initial condition,
- `t_s` are the times at which we require the solution to be evaluated,
- `theta, x_r, x_i` are arguments to be passed to $f$.

Now we have all ingredients to solve our ODE.

Note that in our example, because we assume that the total population remains constant, the three derivatives $\frac{dS}{dt},\frac{dI}{dt},\frac{dR}{dt}$ sum up to $0$. We can use this fact to improve computational efficiency of the `sir` functions by deriving the value of $\frac{dI}{dt}$ from $\frac{dS}{dt}$ and $\frac{dR}{dt}$ :

```
      real dS_dt = -beta * I * S / N;
      real dR_dt =  gamma * I;
      real dI_dt =  -(dS_dt + dR_dt);

```

## remaining Stan code blocks

We will now go through the remaining Stan code blocks.

We declare the data in the `data` block:

```
data {
  int<lower=1> n_days;
  real y0[3];
  real t0;
  real ts[n_days];
  int N;
  int cases[n_days];
}
```

where

- `n_days` is the number of days we observed
- `y0` is the vector of compartments

We code transforms of the data in the `transformed data block`. In this example, we transform our data to match the signature of `sir` (with `x_r` being of length 0 because we have nothing to put in it).

```
transformed data {
  real x_r[0];
  int x_i[1] = { N };
}
```

We next declare the model parameters. If some parameter are bounded, and it is not already guaranteed by his prior, we use `<lower=a, upper=b>` to specify this when declaring the corresponding parameter. This way we can put a truncated prior distribution on a parameter.

```
parameters {
  real<lower=0> gamma;
  real<lower=0> beta;
  real<lower=0> phi_inv;
}
```

The parameters transform as follows:

```
transformed parameters{
  real y[n_days, 3];
  real phi = 1. / phi_inv;
  {
    real theta[2];
    theta[1] = beta;
    theta[2] = gamma;

    y = integrate_ode_rk45(sir, y0, t0, ts, theta, x_r, x_i);
  }
}
```

Given the ODE solution $y$, the only thing left to do is to code the prior and sampling distribution.

```
model {
  //priors
  beta ~ normal(2, 1); //truncated at 0
  gamma ~ normal(0.4, 0.5); //truncated at 0
  phi_inv ~ exponential(5);
  
  //sampling distribution
  //col(matrix x, int n) - The n-th column of matrix x. Here the number of infected people
  cases ~ neg_binomial_2(col(to_matrix(y), 2), phi);
}
```

Untangled from the inference, we can calculate the basic reproduction number, $R_0$, and predictions for the number of cases in the `generated quantities` block:


```
generated quantities {
  real R0 = beta / gamma;
  real recovery_time = 1 / gamma;
  real pred_cases[n_days];
  pred_cases = neg_binomial_2_rng(col(to_matrix(y), 2) + 1e-5, phi);
}
```

## complete program

We put the `Stan` code into a string

```{r completeStanModel}
sir_model <- "
functions {
  real[] sir(real t, real[] y, real[] theta, 
             real[] x_r, int[] x_i) {

      real S = y[1];
      real I = y[2];
      real R = y[3];
      real N = x_i[1];
      
      real beta = theta[1];
      real gamma = theta[2];
      
      real dS_dt = -beta * I * S / N;
      real dI_dt =  beta * I * S / N - gamma * I;
      real dR_dt =  gamma * I;
      
      return {dS_dt, dI_dt, dR_dt};
  }
}
data {
  int<lower=1> n_days;
  real y0[3];
  real t0;
  real ts[n_days];
  int N;
  int cases[n_days];
}
transformed data {
  real x_r[0];
  int x_i[1] = { N };
}
parameters {
  real<lower=0> gamma;
  real<lower=0> beta;
  real<lower=0> phi_inv;
}
transformed parameters{
  real y[n_days, 3];
  real phi = 1. / phi_inv;
  {
    real theta[2];
    theta[1] = beta;
    theta[2] = gamma;

    y = integrate_ode_rk45(sir, y0, t0, ts, theta, x_r, x_i);
  }
}
model {
  //priors
  beta ~ normal(2, 1);
  gamma ~ normal(0.4, 0.5);
  phi_inv ~ exponential(5);
  
  //sampling distribution
  //col(matrix x, int n) - The n-th column of matrix x. Here the number of infected people 
  cases ~ neg_binomial_2(col(to_matrix(y), 2), phi);
}
generated quantities {
  real R0 = beta / gamma;
  real recovery_time = 1 / gamma;
  real pred_cases[n_days];
  pred_cases = neg_binomial_2_rng(col(to_matrix(y), 2), phi);
}

"
```

and put the data in a list

```{r DataToListConversion}
# time series of cases
cases <- df$in_bed  # Number of students in bed

# total count
N <- 763;

# times
n_days <- length(cases) 
t <- seq(0, n_days, by = 1)
t0 = 0 
t <- t[-1]

#initial conditions
i0 <- 1
s0 <- N - i0
r0 <- 0
y0 = c(S = s0, I = i0, R = r0)

# data for Stan
data_sir <- list(n_days = n_days, y0 = y0, t0 = t0, ts = t, N = N, cases = cases)

# number of MCMC steps
niter <- 2000
```

We draw samples from the model by:

```{r, eval=FALSE}
model <- stan(model_code = sir_model, data = data_sir, iter = niter, chains = 4)
```

Or we can construct an instance of S4 class stanmodel from a model specified in Stan's modeling language, which we stored in a file `sir_negbin.stan`. This file simply contains above string.

```{r compileModel, cache=TRUE}
model <- stan_model("sir_negbin.stan")
```

```{r drawSamplesFromModel, eval=TRUE}
fit_sir_negbin <- sampling(model,
                data = data_sir,
                iter = niter,
                chains = 4)
```

## checking the inference

`Stan` gives us information to evaluate whether the statistical inference is reliable. First we start with a summary table of the results for the parameter of interest. Additionally we will see some useful diagnostics, like `Rhat` and the effective sample size.

```{r basicConvergenceCheck}
pars=c('beta', 'gamma', "R0", "recovery_time")
print(fit_sir_negbin, pars = pars)
```

Let us briefly discuss the output above :

- The Gelman-Rubin diagnositc `Rhat` is close to 1, which is a necessary condition for convergence. According to [Brooks and Gelman, 1998]("General methods for monitoring convergence of iterative simulations. Journal of Computational and Graphical Statistics 7: 434â€“455") an `Rhat`value bigger than 1,2 for any of the model parameters should indicate nonconvergence
- The effective sample size `n_eff` is "large" the marcov chains should have explored the parameter space well.

Moreover a trace plot can be used to evaluate if the chains were able to explore the parameter space or got stuck in an area:

```{r traceplot}
traceplot(fit_sir_negbin, pars = pars)
```

But we can also check the posterior distribution of our parameters of interest for each marcov chain. Precisely we can check whether they agree with one another or not:

```{r MarcovChainComparison}
stan_dens(fit_sir_negbin, pars = pars, separate_chains = TRUE)
```

Let us recall the meaning of the parameters

- $\beta$ is the infection rate, assumed to be constant,
- $\gamma$ is the recovery rate, assumed to be constant,
- $R_0$ is the (basic) reproduction number


## checking the model

As we have trust in our model, let us check its utility. Utility is problem specific and can include the precise estimation of a quantity or predicting future behaviors. In general, it is good to check if our fitted model produces simulations that are consistent with the observed data. This is the idea behind *posterior predictive checks*.

We sample predictions $D_{pred}$ from $p(D_{pred}|D)$. Then we use these samples to construct a fitted curve for students in bed, together with the uncertainty, e.g. the 90% interval, which means that 10% of the observed data is expected to fall outside of this interval. This *posterior predictive check* allows us to verify if the model captures the structure of the data:

```{r posteriorPredictiveCheck}
smr_pred <- cbind(as.data.frame(summary(
  fit_sir_negbin, pars = "pred_cases", probs = c(0.05, 0.5, 0.95))$summary), t, cases)
# remove % in the col names
colnames(smr_pred) <- make.names(colnames(smr_pred)) 

ggplot(smr_pred, mapping = aes(x = t)) +
  geom_ribbon(aes(ymin = X5., ymax = X95.), fill = "orange", alpha = 0.6) +
  geom_line(mapping = aes(x = t, y = X50.)) + 
  geom_point(mapping = aes(y = cases)) +
  labs(x = "Day", y = "Number of students in bed")
```


If we want to access the true number of infected people at each time, and not just the number of students in bed, we use the latent variable $I(t)$ for which we have an estimation.

```{r}
#number of infected for each day
params <- lapply(t, function(i){sprintf("y[%s,2]", i)}) 

smr_y <- as.data.frame(summary(fit_sir_negbin, 
                               pars = params, probs = c(0.05, 0.5, 0.95))$summary)
# remove % in the col names
colnames(smr_y) <- make.names(colnames(smr_y)) 

ggplot(smr_y, mapping = aes(x = t)) +
  geom_ribbon(aes(ymin = X5., ymax = X95.), fill = "orange", alpha = 0.6) +
  geom_line(mapping = aes(x = t, y = X50.)) + 
  labs(x = "Day", y = "Number of infected students")
```

# Understand our model by simulated data {.tabset}

In our example we fitted a model to a well-understood data set. In practice we must proceed mode cautiously and probe the behavoir of our model and our inference algorithm. Here working with fake data can be productive.

## chechking our priors

We can check our prior by computing the a priori probability of various epidemiological parameters of interst. In our example we know from domain knowledge that the replication rate $R_0$ of influenza is typically between 1 and 2 and its recovery time $\gamma$ is approximately one week.

We want priors that allow for every reasonable configurations of the data but exclude absurd scenarios, per our domain expertise. To check if our priors fulfill this role, we can do a *prior predictive check*.

To conduct a prior predictive check, we take the same model as before, put the parameters of interest in the `generated_quantities code` block, and remove the sampling distribution term from the model. Without the sampling distribution, the parameters are not fitted to the data and are thus sampled from their prior distribution. The Stan code is thus the same as the final Stan code, without 
```
cases~ neg_binomial_2(col(to_matrix(y), 2), phi);
```

We did this in a file `sir_prior.stan`. We will fit the model and sample from it:

```{r PriorModel, cache=TRUE}
model_priorcheck <- stan_model("sir_prior.stan")
fit_sir_prior <- sampling(model_priorcheck,
                 data = data_sir, seed = 0, chains = 4)
```

This way we got samples from the prior distribution of the parameters, which we can visualize. For example we can look at the distribution of the $\log$ of the recovery time :

```{r}
s_prior <- rstan::extract(fit_sir_prior)
df_test <- tibble(r = s_prior$recovery_time)
ggplot(data = df_test) + 
  geom_histogram(mapping = aes(x = r), bins = 30) + 
  labs(x = "log(recovery time)") + 
  geom_vline(xintercept = 0.5, color = "red") + 
  geom_vline(xintercept = 30, color = "red") +
  scale_x_log10()
```


The red bars showing bounds on the recovery time (1/2 day and 30 days). Most of the probality mass is between the red bars but still more extreme values are allowed, which means that our posterior can concentrate outside the bars, if the data warrants it.

The same thing can be done with $R_0$ (again on a log scale). Here the loose bounds are $0.3$ and $30$


```{r}
df_test <- tibble(r = s_prior$R0)
ggplot(data = df_test) + 
  geom_histogram(mapping = aes(x = r), bins = 30) + 
  labs(x = "log(R0)") + 
  geom_vline(xintercept = 0.3, color = "red") + 
  geom_vline(xintercept = 30, color = "red") + 
  scale_x_log10()
```

## Can our inference algorithm recover the right parameters?

While there exist many theoretical guarantees for MCMC algorithms, modelers should realize that these rely on a set of assumptions which are not always easy to verify and that many of these guarantees are asymptotic. This means they are proven in the limit where we have an infinite number of samples from the posterior distribution. A very nice, if advanced, review on the subject can be found in Roberts and Rosenthal ([2004](https://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html#ref-Roberts_mcmc_2004))


# References

TBD